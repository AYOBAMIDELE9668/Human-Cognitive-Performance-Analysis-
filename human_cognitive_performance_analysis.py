# -*- coding: utf-8 -*-
"""Human Cognitive Performance Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kZ0lTE59lepRm3F93bGvGlsXYrwB9pe6
"""

import pandas as pd  # For data manipulation
import numpy as np  # For numerical operations
import matplotlib.pyplot as plt  # For plotting
import seaborn as sns  # For advanced visualizations
from sklearn.model_selection import train_test_split  # For splitting data
from sklearn.ensemble import RandomForestRegressor  # For regression modeling
from sklearn.metrics import mean_squared_error, r2_score  # For evaluating models
from sklearn.cluster import KMeans  # For clustering
from sklearn.preprocessing import StandardScaler  # For scaling features

df = pd.read_csv('human_cognitive_performance.csv',)

print(df.head(5))

# Check basic information about the dataset
print("\nDataset Information:")
print(df.info())

# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# Summary statistics
print("\nSummary Statistics:")
print(df.describe())

# Visualize the distribution of the Cognitive Score
plt.figure(figsize=(10, 6))
sns.histplot(df['Cognitive_Score'], kde=True, bins=30, color='blue')
plt.title('Distribution of Cognitive Scores')
plt.xlabel('Cognitive Score')
plt.ylabel('Frequency')
plt.show()

# Correlation heatmap to identify relationships between variables
plt.figure(figsize=(12, 8))
# Exclude non-numeric columns from correlation calculation
numerical_df = df.select_dtypes(include=np.number)  # Select only numerical columns
correlation_matrix = numerical_df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

# Encode categorical variables (e.g., Gender, Diet_Type)
df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0, 'Other': 2})
diet_mapping = {'Non-Vegetarian': 0, 'Vegetarian': 1, 'Vegan': 2}
df['Diet_Type'] = df['Diet_Type'].map(diet_mapping)

# Drop the User_ID column as it doesn't contribute to predictions
df.drop(columns=['User_ID'], inplace=True)

# Split the data into features (X) and target (y)
X = df.drop(columns=['Cognitive_Score', 'AI_Predicted_Score'])
y = df['Cognitive_Score']

# Scale numerical features
scaler = StandardScaler()
# Select only numerical features for scaling
numerical_features = X.select_dtypes(include=np.number).columns
X_scaled = pd.DataFrame(scaler.fit_transform(X[numerical_features]), columns=numerical_features, index=X.index)
# If you need to keep the original columns, you can concatenate the scaled and non-scaled features:
#X = pd.concat([X_scaled, X.drop(columns=numerical_features)], axis=1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train a Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")
print(f"R^2 Score: {r2:.2f}")

# Plot actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7, color='green')
plt.plot([y.min(), y.max()], [y.min(), y.max()], '--', color='red')  # Ideal line
plt.title('Actual vs Predicted Cognitive Scores')
plt.xlabel('Actual Scores')
plt.ylabel('Predicted Scores')
plt.show()

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

df['Cluster'] = clusters

# Analyze the clusters
print("\nCluster Distribution:")
print(df['Cluster'].value_counts())

# Visualize clusters using PCA for dimensionality reduction
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='Set1')
plt.title('Clusters of Individuals Based on Lifestyle Patterns')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()

import joblib

# Save the trained Random Forest model
joblib.dump(rf_model, 'cognitive_performance_model.pkl')

# To load the model later:
# loaded_model = joblib.load('cognitive_performance_model.pkl')